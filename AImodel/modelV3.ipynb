{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "OmO7jmrpkvZf"
   },
   "outputs": [],
   "source": [
    "# import the dataset\n",
    "import pandas as pd\n",
    "problems_df = pd.read_csv('ppp.csv')\n",
    "target_df = pd.read_csv('tar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of movies dataframe are: (20114, 12) \n",
      "The dimensions of ratings dataframe are: (8270, 3)\n"
     ]
    }
   ],
   "source": [
    "print('The dimensions of movies dataframe are:', problems_df.shape,'\\nThe dimensions of ratings dataframe are:', target_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems_df.drop(['Submission_Id','User_Rating'], axis=1, inplace=True)\n",
    "problems_df.drop(['Problem_Rating','Unnamed: 7','Unnamed: 8','Unnamed: 9','Unnamed: 10','Unnamed: 11'],axis=1,inplace=True)\n",
    "result_df = problems_df.drop_duplicates(subset=['Problem Name'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of movies dataframe are: (20114, 4) \n",
      "The dimensions of ratings dataframe are: (8270, 3)\n"
     ]
    }
   ],
   "source": [
    "print('The dimensions of movies dataframe are:', problems_df.shape,'\\nThe dimensions of ratings dataframe are:', target_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "ALPeuAiBk0mM",
    "outputId": "8afc063a-7b73-4cdf-b624-cf36ecfa231a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob_id</th>\n",
       "      <th>Problem Name</th>\n",
       "      <th>User_Name</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1037CEqualize</td>\n",
       "      <td>akshayjadhav7670</td>\n",
       "      <td>['dp', 'greedy', 'strings']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>266BQueue at the School</td>\n",
       "      <td>aryans_18</td>\n",
       "      <td>['constructive algorithms', 'graph matchings',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1583BOmkar and Heavenly Tree</td>\n",
       "      <td>abhishek_s3107</td>\n",
       "      <td>['constructive algorithms', 'trees']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>112APetya and Strings</td>\n",
       "      <td>fjafari</td>\n",
       "      <td>['implementation', 'strings']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>443AAnton and Letters</td>\n",
       "      <td>manish_rohila</td>\n",
       "      <td>['constructive algorithms', 'implementation']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prob_id                  Problem Name         User_Name  \\\n",
       "0        1                 1037CEqualize  akshayjadhav7670   \n",
       "1        2       266BQueue at the School         aryans_18   \n",
       "2        3  1583BOmkar and Heavenly Tree    abhishek_s3107   \n",
       "3        4         112APetya and Strings           fjafari   \n",
       "4        5         443AAnton and Letters     manish_rohila   \n",
       "\n",
       "                                                Tags  \n",
       "0                        ['dp', 'greedy', 'strings']  \n",
       "1  ['constructive algorithms', 'graph matchings',...  \n",
       "2               ['constructive algorithms', 'trees']  \n",
       "3                      ['implementation', 'strings']  \n",
       "4      ['constructive algorithms', 'implementation']  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at movies_df\n",
    "problems_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df['TargetVariable'] = 10* target_df['TargetVariable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tar_id</th>\n",
       "      <th>User_ID</th>\n",
       "      <th>TargetVariable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.558140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4.736842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tar_id  User_ID  TargetVariable\n",
       "0       1        1        2.558140\n",
       "1       2        1        3.538462\n",
       "2       3        1        4.000000\n",
       "3       4        1        2.615385\n",
       "4       5        1        4.736842"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2TUaWt96k0q7",
    "outputId": "afd13baa-d03e-40c9-9dcf-f8c4cbda08d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 8270\n",
      "Number of unique problems: 20114\n",
      "The full rating matrix will have: 166342780 elements.\n",
      "----------\n",
      "Number of ratings: 8270\n",
      "Therefore:  0.004971661529283087 % of the matrix is filled.\n",
      "We have an incredibly sparse matrix to work with here.\n",
      "And... as you can imagine, as the number of users and products grow, the number of elements will increase by n*2\n",
      "You are going to need a lot of memory to work with global scale... storing a full matrix in memory would be a challenge.\n",
      "One advantage here is that matrix factorization can realize the rating matrix implicitly, thus we don't need all the data\n"
     ]
    }
   ],
   "source": [
    "# Movie ID to movie name mapping\n",
    "problem_name = problems_df.set_index('prob_id')['Problem Name'].to_dict()\n",
    "\n",
    "n_probs = len(problems_df.prob_id.unique())#not sure whats happening here  #n_user changed to n_probs\n",
    "\n",
    "n_items = len(target_df.tar_id.unique())\n",
    "print(\"Number of unique users:\", n_items)\n",
    "print(\"Number of unique problems:\", n_probs)\n",
    "print(\"The full rating matrix will have:\", n_probs*n_items, 'elements.')\n",
    "print('----------')\n",
    "print(\"Number of ratings:\", len(target_df))\n",
    "print(\"Therefore: \", len(target_df) / (n_probs*n_items) * 100, '% of the matrix is filled.')\n",
    "print(\"We have an incredibly sparse matrix to work with here.\")\n",
    "print(\"And... as you can imagine, as the number of users and products grow, the number of elements will increase by n*2\")\n",
    "print(\"You are going to need a lot of memory to work with global scale... storing a full matrix in memory would be a challenge.\")\n",
    "print(\"One advantage here is that matrix factorization can realize the rating matrix implicitly, thus we don't need all the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "YnkTvMsCk0tY"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "class MatrixFactorization(torch.nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "        # create user embeddings\n",
    "        self.user_factors = torch.nn.Embedding(n_users, n_factors) # think of this as a lookup table for the input.\n",
    "        # create item embeddings\n",
    "        self.item_factors = torch.nn.Embedding(n_items, n_factors) # think of this as a lookup table for the input.\n",
    "        self.user_factors.weight.data.uniform_(0, 0.05)\n",
    "        self.item_factors.weight.data.uniform_(0, 0.05)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        # matrix multiplication\n",
    "        #users = data[:,0]\n",
    "        #print(\"Users: \",users)\n",
    "        users, items = data[:,0], data[:,1]\n",
    "        return (self.user_factors(users)*self.item_factors(items)).sum(1)\n",
    "    # def forward(self, user, item):\n",
    "    # \t# matrix multiplication\n",
    "    #     return (self.user_factors(user)*self.item_factors(item)).sum(1)\n",
    "    \n",
    "    def predict(self, user, item):\n",
    "        return self.forward(user, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "LTlGvz7sk0v2"
   },
   "outputs": [],
   "source": [
    "# Creating the dataloader (necessary for PyTorch)\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader # package that helps transform your data to machine learning readiness\n",
    "\n",
    "# Note: This isn't 'good' practice, in a MLops sense but we'll roll with this since the data is already loaded in memory.\n",
    "class Loader(Dataset):\n",
    "    def __init__(self):\n",
    "        self.ratings = target_df.copy()#changed ratings to target\n",
    "        \n",
    "        # Extract all user IDs and movie IDs\n",
    "        users = target_df.tar_id.unique()      ###changine user_id to tar_id\n",
    "        movies = target_df.tar_id.unique()      ##i changed somethng\n",
    "        \n",
    "        #--- Producing new continuous IDs for users and movies ---\n",
    "        \n",
    "        # Unique values : index\n",
    "        self.userid2idx = {o:i for i,o in enumerate(users)}\n",
    "        self.movieid2idx = {o:i for i,o in enumerate(movies)}\n",
    "        \n",
    "        # Obtained continuous ID for users and movies\n",
    "        self.idx2userid = {i:o for o,i in self.userid2idx.items()}\n",
    "        self.idx2movieid = {i:o for o,i in self.movieid2idx.items()}\n",
    "        \n",
    "        # return the id from the indexed values as noted in the lambda function down below.\n",
    "        self.ratings.tar_id = target_df.tar_id.apply(lambda x: self.movieid2idx[x])\n",
    "        self.ratings.tar_id = target_df.tar_id.apply(lambda x: self.userid2idx[x])\n",
    "        \n",
    "        \n",
    "        self.x = self.ratings.drop(['TargetVariable'], axis=1).values\n",
    "        self.y = self.ratings['TargetVariable'].values\n",
    "        self.x, self.y = torch.tensor(self.x), torch.tensor(self.y) # Transforms the data to tensors (ready for torch models.)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J6MK3Ymmk0yi",
    "outputId": "50e960e6-ccc7-4852-98cf-55144f7848c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is running on GPU: True\n",
      "MatrixFactorization(\n",
      "  (user_factors): Embedding(20114, 8)\n",
      "  (item_factors): Embedding(8270, 8)\n",
      ")\n",
      "user_factors.weight tensor([[0.0258, 0.0254, 0.0470,  ..., 0.0166, 0.0351, 0.0372],\n",
      "        [0.0020, 0.0379, 0.0305,  ..., 0.0405, 0.0244, 0.0449],\n",
      "        [0.0481, 0.0455, 0.0187,  ..., 0.0417, 0.0186, 0.0283],\n",
      "        ...,\n",
      "        [0.0445, 0.0235, 0.0447,  ..., 0.0030, 0.0122, 0.0469],\n",
      "        [0.0399, 0.0161, 0.0317,  ..., 0.0023, 0.0098, 0.0266],\n",
      "        [0.0401, 0.0435, 0.0430,  ..., 0.0317, 0.0230, 0.0140]])\n",
      "item_factors.weight tensor([[0.0091, 0.0303, 0.0481,  ..., 0.0172, 0.0451, 0.0373],\n",
      "        [0.0075, 0.0144, 0.0316,  ..., 0.0215, 0.0332, 0.0278],\n",
      "        [0.0374, 0.0387, 0.0200,  ..., 0.0244, 0.0134, 0.0033],\n",
      "        ...,\n",
      "        [0.0096, 0.0178, 0.0375,  ..., 0.0322, 0.0389, 0.0474],\n",
      "        [0.0321, 0.0438, 0.0468,  ..., 0.0289, 0.0307, 0.0468],\n",
      "        [0.0014, 0.0440, 0.0241,  ..., 0.0430, 0.0065, 0.0030]])\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 128\n",
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "print(\"Is running on GPU:\", cuda)\n",
    "\n",
    "model = MatrixFactorization(n_probs, n_items, n_factors=8)\n",
    "print(model)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "# GPU enable if you have a GPU...\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "# MSE loss\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "# ADAM optimizier\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Train data\n",
    "train_set = Loader()\n",
    "train_loader = DataLoader(train_set, 128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "3c1765cabeaf4d75a130311ddc4591a1",
      "6db170b52f5a4f72afd083a3a9c157aa",
      "69073fd458234bba829af9731b4fce1c",
      "88151edb53134487b95f6bcbcd7fd2b4",
      "9b185906b1dc465e93b9f058a1fec47a",
      "20b4738815cd467dba2946031d6d9027",
      "c279f9a0a0fe498b9db167a237517e6e",
      "005a499c40bd407ca20c2492d9c4f170"
     ]
    },
    "id": "8fIDIdStk000",
    "outputId": "84caf390-d372-4d82-a045-cbf12a9c8cce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5465/59576823.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for it in tqdm(range(num_epochs)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "451b3556418b454e9bfbe18d1856b275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #0 Loss: 20.042263999352087\n",
      "iter #1 Loss: 20.01335082420936\n",
      "iter #2 Loss: 19.95858550438514\n",
      "iter #3 Loss: 19.93229475754958\n",
      "iter #4 Loss: 19.848736190795897\n",
      "iter #5 Loss: 19.761001088069037\n",
      "iter #6 Loss: 19.653706770676834\n",
      "iter #7 Loss: 19.53711797274076\n",
      "iter #8 Loss: 19.39386869577261\n",
      "iter #9 Loss: 19.233802766066333\n",
      "iter #10 Loss: 19.06382654630221\n",
      "iter #11 Loss: 18.87173796433669\n",
      "iter #12 Loss: 18.636272694514346\n",
      "iter #13 Loss: 18.419211666400617\n",
      "iter #14 Loss: 18.186318646944486\n",
      "iter #15 Loss: 17.933418919489934\n",
      "iter #16 Loss: 17.66324261885423\n",
      "iter #17 Loss: 17.381022321260893\n",
      "iter #18 Loss: 17.088177666297327\n",
      "iter #19 Loss: 16.79549692594088\n",
      "iter #20 Loss: 16.499397424551155\n",
      "iter #21 Loss: 16.1632602251493\n",
      "iter #22 Loss: 15.83986599261944\n",
      "iter #23 Loss: 15.522537480867825\n",
      "iter #24 Loss: 15.190907947833722\n",
      "iter #25 Loss: 14.845280691293569\n",
      "iter #26 Loss: 14.486412796607384\n",
      "iter #27 Loss: 14.128478226294884\n",
      "iter #28 Loss: 13.79577991779034\n",
      "iter #29 Loss: 13.440299356900729\n",
      "iter #30 Loss: 13.08814158806434\n",
      "iter #31 Loss: 12.73156193953294\n",
      "iter #32 Loss: 12.359797169612005\n",
      "iter #33 Loss: 12.002377876868614\n",
      "iter #34 Loss: 11.64155170734112\n",
      "iter #35 Loss: 11.272100184513972\n",
      "iter #36 Loss: 10.925015053382287\n",
      "iter #37 Loss: 10.58453278174767\n",
      "iter #38 Loss: 10.224205559950608\n",
      "iter #39 Loss: 9.881699679448054\n",
      "iter #40 Loss: 9.532724123734694\n",
      "iter #41 Loss: 9.189427727919359\n",
      "iter #42 Loss: 8.8546312552232\n",
      "iter #43 Loss: 8.533280812777006\n",
      "iter #44 Loss: 8.193133647625263\n",
      "iter #45 Loss: 7.876590926830585\n",
      "iter #46 Loss: 7.551149199559139\n",
      "iter #47 Loss: 7.245898862985464\n",
      "iter #48 Loss: 6.94302946971013\n",
      "iter #49 Loss: 6.637374129662147\n",
      "iter #50 Loss: 6.347222827031062\n",
      "iter #51 Loss: 6.062083911895752\n",
      "iter #52 Loss: 5.789983910780687\n",
      "iter #53 Loss: 5.525308286226712\n",
      "iter #54 Loss: 5.25210359279926\n",
      "iter #55 Loss: 4.998594218034011\n",
      "iter #56 Loss: 4.739687747221726\n",
      "iter #57 Loss: 4.50129658625676\n",
      "iter #58 Loss: 4.268964617068951\n",
      "iter #59 Loss: 4.038889976648184\n",
      "iter #60 Loss: 3.82130205814655\n",
      "iter #61 Loss: 3.607388423039363\n",
      "iter #62 Loss: 3.4079576345590445\n",
      "iter #63 Loss: 3.209564025585468\n",
      "iter #64 Loss: 3.018148077451266\n",
      "iter #65 Loss: 2.8378965561206524\n",
      "iter #66 Loss: 2.66688129901886\n",
      "iter #67 Loss: 2.5009362404163067\n",
      "iter #68 Loss: 2.3378543743720424\n",
      "iter #69 Loss: 2.1840776535180897\n",
      "iter #70 Loss: 2.036123670064486\n",
      "iter #71 Loss: 1.8965852187230037\n",
      "iter #72 Loss: 1.7695124314381525\n",
      "iter #73 Loss: 1.6447069809986994\n",
      "iter #74 Loss: 1.5236303017689632\n",
      "iter #75 Loss: 1.4130963508899395\n",
      "iter #76 Loss: 1.307278443299807\n",
      "iter #77 Loss: 1.2045928597450257\n",
      "iter #78 Loss: 1.1113715226833636\n",
      "iter #79 Loss: 1.0261302828788756\n",
      "iter #80 Loss: 0.9391323713155894\n",
      "iter #81 Loss: 0.8636214412175692\n",
      "iter #82 Loss: 0.7896513310762552\n",
      "iter #83 Loss: 0.7229384747835306\n",
      "iter #84 Loss: 0.6590011289486518\n",
      "iter #85 Loss: 0.6013117817732004\n",
      "iter #86 Loss: 0.5471401361318735\n",
      "iter #87 Loss: 0.4949962393595622\n",
      "iter #88 Loss: 0.4481558666779445\n",
      "iter #89 Loss: 0.40462981852201313\n",
      "iter #90 Loss: 0.36631351250868577\n",
      "iter #91 Loss: 0.32894168347120284\n",
      "iter #92 Loss: 0.29549284050097835\n",
      "iter #93 Loss: 0.2650500720510116\n",
      "iter #94 Loss: 0.23667725863365027\n",
      "iter #95 Loss: 0.21241161261613553\n",
      "iter #96 Loss: 0.18822574019432067\n",
      "iter #97 Loss: 0.16831306494199313\n",
      "iter #98 Loss: 0.1487654393682113\n",
      "iter #99 Loss: 0.13149176423366254\n",
      "iter #100 Loss: 0.11687051682518079\n",
      "iter #101 Loss: 0.10214548775782951\n",
      "iter #102 Loss: 0.09053099413330738\n",
      "iter #103 Loss: 0.0785360995393533\n",
      "iter #104 Loss: 0.06993192657828332\n",
      "iter #105 Loss: 0.06010854780100859\n",
      "iter #106 Loss: 0.0522495988326577\n",
      "iter #107 Loss: 0.04532187730073929\n",
      "iter #108 Loss: 0.039258955433391605\n",
      "iter #109 Loss: 0.03373278664568296\n",
      "iter #110 Loss: 0.029174237583692256\n",
      "iter #111 Loss: 0.024902758482270516\n",
      "iter #112 Loss: 0.021538334103444447\n",
      "iter #113 Loss: 0.018227193103386805\n",
      "iter #114 Loss: 0.01554868476322064\n",
      "iter #115 Loss: 0.013115562050818251\n",
      "iter #116 Loss: 0.011117292768680133\n",
      "iter #117 Loss: 0.009365032663425574\n",
      "iter #118 Loss: 0.007823527621356054\n",
      "iter #119 Loss: 0.006521138501389382\n",
      "iter #120 Loss: 0.005435927299997555\n",
      "iter #121 Loss: 0.0044891761356176665\n",
      "iter #122 Loss: 0.0037216279243763822\n",
      "iter #123 Loss: 0.0030860125485700197\n",
      "iter #124 Loss: 0.0025038875205119927\n",
      "iter #125 Loss: 0.0020477461081239968\n",
      "iter #126 Loss: 0.001644920900994643\n",
      "iter #127 Loss: 0.0013280576698329802\n"
     ]
    }
   ],
   "source": [
    "for it in tqdm(range(num_epochs)):\n",
    "    losses = []\n",
    "    for x, y in train_loader:\n",
    "         if cuda:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = loss_fn(outputs.squeeze(), y.type(torch.float32))\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    print(\"iter #{}\".format(it), \"Loss:\", sum(losses) / len(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zs_GVbSYmhib",
    "outputId": "d4a5a7f6-f2a6-4d08-9083-84a2812c3f45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_factors.weight tensor([[0.2321, 0.2292, 0.2462,  ..., 0.2181, 0.2336, 0.2380],\n",
      "        [0.3099, 0.3430, 0.3293,  ..., 0.3430, 0.3227, 0.3462],\n",
      "        [0.3871, 0.3811, 0.3481,  ..., 0.3751, 0.3475, 0.3602],\n",
      "        ...,\n",
      "        [0.0445, 0.0235, 0.0447,  ..., 0.0030, 0.0122, 0.0469],\n",
      "        [0.0399, 0.0161, 0.0317,  ..., 0.0023, 0.0098, 0.0266],\n",
      "        [0.0401, 0.0435, 0.0430,  ..., 0.0317, 0.0230, 0.0140]],\n",
      "       device='cuda:0')\n",
      "item_factors.weight tensor([[9.1464e-03, 3.0326e-02, 4.8137e-02,  ..., 1.7189e-02, 4.5065e-02,\n",
      "         3.7301e-02],\n",
      "        [1.3298e+00, 1.3602e+00, 1.3911e+00,  ..., 1.3493e+00, 1.3768e+00,\n",
      "         1.3805e+00],\n",
      "        [7.5468e-01, 7.2884e-01, 7.2583e-01,  ..., 7.0469e-01, 7.0961e-01,\n",
      "         6.7983e-01],\n",
      "        ...,\n",
      "        [9.6250e-03, 1.7837e-02, 3.7526e-02,  ..., 3.2151e-02, 3.8916e-02,\n",
      "         4.7398e-02],\n",
      "        [3.2081e-02, 4.3751e-02, 4.6777e-02,  ..., 2.8914e-02, 3.0730e-02,\n",
      "         4.6779e-02],\n",
      "        [1.3634e-03, 4.4032e-02, 2.4109e-02,  ..., 4.2974e-02, 6.5244e-03,\n",
      "         3.0306e-03]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# By training the model, we will have tuned latent factors for movies and users.\n",
    "c = 0\n",
    "uw = 0\n",
    "iw = 0 \n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "        if c == 0:\n",
    "          uw = param.data\n",
    "          c +=1\n",
    "        else:\n",
    "          iw = param.data\n",
    "        #print('param_data', param_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "IJgie01_p8k5"
   },
   "outputs": [],
   "source": [
    "trained_movie_embeddings = model.item_factors.weight.data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R-_tHZ_E_rub",
    "outputId": "cb97ce5d-7140-43fa-8ffa-7603a22eee2c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8270"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trained_movie_embeddings) # unique movie factor weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "bl9s4iqXy75q"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# Fit the clusters based on the movie weights\n",
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(trained_movie_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8MDzp-9u-m5n",
    "outputId": "c6f77e4d-68d1-49c5-c022-25e80e99007d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster #0\n",
      "\t 112APetya and Strings\n",
      "\t 513G2Inversions problem\n",
      "\t 1521ANastia and Nearly Good Numbers\n",
      "\t 236ABoy or Girl\n",
      "\t 1480CSearching Local Minimum\n",
      "\t 1592AGamer Hemose\n",
      "\t 1480CSearching Local Minimum\n",
      "\t 124AThe number of positions\n",
      "\t 676CVasya and String\n",
      "\t 312BArcher\n",
      "Cluster #1\n",
      "\t 616BDinner with Emma\n",
      "\t 1642CGreat Sequence\n",
      "\t 1398ABad Triangle\n",
      "\t 1578EEasy Scheduling\n",
      "\t 1335ACandies and Two Sisters\n",
      "\t 771ABear and Friendship Condition\n",
      "\t 932BRecursive Queries\n",
      "\t 1556BTake Your Places!\n",
      "\t 550BPreparing Olympiad\n",
      "\t 371CHamburgers\n",
      "Cluster #2\n",
      "\t 1037CEqualize\n",
      "\t 496AMinimum Difficulty\n",
      "\t 977AWrong Subtraction\n",
      "\t 143AHelp Vasilisa the Wise 2\n",
      "\t 1562BScenes From a Memory\n",
      "\t 449BJzzhu and Cities\n",
      "\t 1633CKill the Monster\n",
      "\t 1644ADoors and Keys\n",
      "\t 1271ASuits\n",
      "\t 1037CEqualize\n",
      "Cluster #3\n",
      "\t 1583BOmkar and Heavenly Tree\n",
      "\t 189ACut Ribbon\n",
      "\t 1406BMaximum Product\n",
      "\t 268BButtons\n",
      "\t 556ACase of the Zeros and Ones\n",
      "\t 1637CAndrew and Stones\n",
      "\t 996AHit the Lottery\n",
      "\t 339AHelpful Maths\n",
      "\t 580AKefa and First Steps\n",
      "\t 158ANext Round\n",
      "Cluster #4\n",
      "\t 1613ALong Comparison\n",
      "\t 102CHomework\n",
      "\t 371CHamburgers\n",
      "\t 96AFootball\n",
      "\t 1490FEqualize the Array\n",
      "\t 796BFind The Bone\n",
      "\t 318AEven Odds\n",
      "\t 1594CMake Them Equal\n",
      "\t 1584CTwo Arrays\n",
      "\t 1634COKEA\n",
      "Cluster #5\n",
      "\t 443AAnton and Letters\n",
      "\t 266BQueue at the School\n",
      "\t 771ABear and Friendship Condition\n",
      "\t 1618ESingers' Tour\n",
      "\t 981AAntipalindrome\n",
      "\t 681CHeap Operations\n",
      "\t 926EMerge Equal Elements\n",
      "\t 1216APrefixes\n",
      "\t 550BPreparing Olympiad\n",
      "\t 189ACut Ribbon\n",
      "Cluster #6\n",
      "\t 579ARaising Bacteria\n",
      "\t 1141AGame 23\n",
      "\t 1632BRoof Construction\n",
      "\t 1362CJohnny and Another Rating Drop\n",
      "\t 144AArrival of the General\n",
      "\t 1504A Déjà Vu\n",
      "\t 1562CRings\n",
      "\t 99BHelp Chef Gerasim\n",
      "\t 160ATwins\n",
      "\t 1266BDice Tower\n",
      "Cluster #7\n",
      "\t 1641ESpecial Positions\n",
      "\t 670D1Magic Powder - 1\n",
      "\t 1594CMake Them Equal\n",
      "\t 405AGravity Flip\n",
      "\t 580AKefa and First Steps\n",
      "\t 260BAncient Prophesy\n",
      "\t 734CAnton and Making Potions\n",
      "\t 1615BAnd It's Non-Zero\n",
      "\t 1446AKnapsack\n",
      "\t 225ADice Tower\n",
      "Cluster #8\n",
      "\t 490ATeam Olympiad\n",
      "\t 1618ESingers' Tour\n",
      "\t 263ABeautiful Matrix\n",
      "\t 4AWatermelon\n",
      "\t 312BArcher\n",
      "\t 151BPhone Numbers\n",
      "\t 1594DThe Number of Imposters\n",
      "\t 490ATeam Olympiad\n",
      "\t 1335ACandies and Two Sisters\n",
      "\t 236ABoy or Girl\n",
      "Cluster #9\n",
      "\t 1556BTake Your Places!\n",
      "\t 1363AOdd Selection\n",
      "\t 1607DBlue-Red Permutation\n",
      "\t 1117CMagic Ship\n",
      "\t 670D1Magic Powder - 1\n",
      "\t 1641ESpecial Positions\n",
      "\t 1352CK-th Not Divisible by n\n",
      "\t 339AHelpful Maths\n",
      "\t 99BHelp Chef Gerasim\n",
      "\t 1634COKEA\n"
     ]
    }
   ],
   "source": [
    "'''m is unfamiliar with the movie name\n",
    "and only obtained the relationships by looking at the numbers representing how\n",
    "users have responded to the movie selections.'''It can be seen here that the movies that are in the same cluster tend to have\n",
    "similar genres. Also note that the algorith\n",
    "for cluster in range(10):\n",
    "  print(\"Cluster #{}\".format(cluster))\n",
    "  movs = []\n",
    "  for movidx in np.where(kmeans.labels_ == cluster)[0]:\n",
    "    movid = train_set.idx2movieid[movidx]\n",
    "    rat_count = target_df.loc[target_df['User_ID']==movid].count()[0]\n",
    "    movs.append((problem_name[movid], rat_count))\n",
    "  for mov in sorted(movs, key=lambda tup: tup[1], reverse=True)[:10]:\n",
    "    print(\"\\t\", mov[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Recommendation_System.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "005a499c40bd407ca20c2492d9c4f170": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20b4738815cd467dba2946031d6d9027": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c1765cabeaf4d75a130311ddc4591a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_69073fd458234bba829af9731b4fce1c",
       "IPY_MODEL_88151edb53134487b95f6bcbcd7fd2b4"
      ],
      "layout": "IPY_MODEL_6db170b52f5a4f72afd083a3a9c157aa"
     }
    },
    "69073fd458234bba829af9731b4fce1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_20b4738815cd467dba2946031d6d9027",
      "max": 128,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9b185906b1dc465e93b9f058a1fec47a",
      "value": 128
     }
    },
    "6db170b52f5a4f72afd083a3a9c157aa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88151edb53134487b95f6bcbcd7fd2b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_005a499c40bd407ca20c2492d9c4f170",
      "placeholder": "​",
      "style": "IPY_MODEL_c279f9a0a0fe498b9db167a237517e6e",
      "value": " 128/128 [03:03&lt;00:00,  1.44s/it]"
     }
    },
    "9b185906b1dc465e93b9f058a1fec47a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c279f9a0a0fe498b9db167a237517e6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
